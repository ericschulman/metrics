{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import IV2SLS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1) - Part 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = .1\n",
    "var = [[1, sigma ], [sigma , 1]]\n",
    "mean = [0., 0.]\n",
    "N = int(1e6)\n",
    "\n",
    "ey, ex = np.random.multivariate_normal(mean, var, size = N).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "pz = .3\n",
    "\n",
    "z = np.random.binomial(1,pz,N).astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0x = -.5\n",
    "beta_1x = 2\n",
    "\n",
    "x = (beta_0x + beta_1x*z + ex > 0).astype(np.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_0y = 1\n",
    "beta_1y = 1\n",
    "\n",
    "y = beta_0y + beta_1y*x + ey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 5\n",
    "\n",
    "$E(y(1) -y(0)) = E(\\beta_{0y} + \\beta_{1jy} + \\epsilon_{yj} |x=1 ) - E(\\beta_{0y} + \\epsilon_{yj} | x_j=0 ) = E(\\beta_{1jy} |x_j =1) = \\beta_{1y} + E(\\epsilon_{yj}|x_j = 1) -E(\\epsilon_{yj}|x_j=0) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.116165139029349"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y1 = (y*x).sum()/x.sum()\n",
    "y0 =  (y*(1-x)).sum()/(1-x).sum()\n",
    "\n",
    "y1 - y0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 6\n",
    "\n",
    "* What happens to the OLS estimator applied to this data?\n",
    "It does not recover the average treatment effect of $X$ on $Y$\n",
    "* Is that expected or unexpected?\n",
    "It is biased upward. This is expected because $X$ is correlated with the error term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 7\n",
    "\n",
    "Using the IV estimator is much closer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1.0016771452554731\n"
     ]
    }
   ],
   "source": [
    "y1 = (y*z).sum()/z.sum()\n",
    "y0 =  (y*(1-z)).sum()/(1-z).sum()\n",
    "\n",
    "x1 = (x*z).sum()/z.sum()\n",
    "x0 =  (x*(1-z)).sum()/(1-z).sum()\n",
    "\n",
    "print (y1 - y0)/(x1 - x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 8 \n",
    "\n",
    "\n",
    "* If $x_i = 1$, and $z_i = 1$ (compliers) then $\\epsilon_{xj} > -\\beta_{0x} - \\beta_{1x}$\n",
    "* If $x_i = 0$, and $z_i = 1$ (never takers) then $\\epsilon_{xj} \\leq -\\beta_{0x} - \\beta_{1x}$\n",
    "* If $x_i = 1$, and $z_i = 0$ (defiers) then $\\epsilon_{xj} > -\\beta_{0x} $\n",
    "* If $x_i = 0$, and $z_i = 0$ (never takers) then $\\epsilon_{xj} \\leq -\\beta_{0x} $\n",
    "\n",
    "\n",
    "### Part 9 \n",
    "\n",
    "Above we can see that defiers have $\\epsilon_{xj} \\leq -\\beta_{0x} + \\beta_{1x}$\n",
    "When  $min(\\epsilon_{xj}) > -\\beta_{0x} + \\beta_{1x}$, we have no defiers\n",
    "\n",
    "### Part 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "compliers: 0.280032\n",
      "never takers: 0.020027\n",
      "defiers: 0.216182\n",
      "never takers: 0.483759\n"
     ]
    }
   ],
   "source": [
    "c = (x*z).sum()/N \n",
    "print 'compliers: %s'%c\n",
    "\n",
    "d = ((1-x)*z).sum()/N\n",
    "print 'never takers: %s'%d\n",
    "\n",
    "a =   (x*(1-z)).sum()/N\n",
    "print 'defiers: %s'%a\n",
    "\n",
    "n= ((1-x)*(1-z)).sum()/N\n",
    "print 'never takers: %s'%n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.095965832826491\n"
     ]
    }
   ],
   "source": [
    "c = ( ex > - beta_0x -  beta_1x ).astype(np.float) \n",
    "\n",
    "x1c = x*c #x is 1 and a complier\n",
    "x0c = (1-x)*c #x is 0 and a complier\n",
    "\n",
    "\n",
    "y1c = (y*x1c).sum()/x1c.sum()\n",
    "y0c =  (y*x0c).sum()/x0c.sum()\n",
    "\n",
    "print y1c - y0c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 12 \n",
    "\n",
    "The average treatment effect is the LATE. The IV estimate is not the LATE\n",
    "\n",
    "### Part 13\n",
    "\n",
    "Since $\\beta_{1jy} =1$ for all $j$, the treatment effect and the local average treatment effect should be the same. Everyone has the same treatment effect essentially. As a result, it is unclear how to interpret the IV estimate\n",
    "\n",
    "### Part 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_1jy = np.random.normal(1, 1, size = N)\n",
    "\n",
    "yj = beta_0y + beta_1jy*x + ey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 15\n",
    "\n",
    "\n",
    "$E(y(1) -y(0)) = E(\\beta_{0y} + \\beta_{1jy} + \\epsilon_{yj} |x=1 ) - E(\\beta_{0y} + \\epsilon_{yj} | x_j=0 ) =  E(\\beta_{1jy} + \\epsilon_{yj}|x_j = 1) -E(\\epsilon_{yj}|x_j=0) $\n",
    "\n",
    "### Part 16\n",
    "\n",
    "Yes it does, this is expected because the individual coefficient was independent from the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.1159159518296389\n"
     ]
    }
   ],
   "source": [
    "yj1 = (yj*x).sum()/x.sum()\n",
    "yj0 =  (yj*(1-x)).sum()/(1-x).sum()\n",
    "\n",
    "print yj1 - yj0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0059753143335015\n"
     ]
    }
   ],
   "source": [
    "yj1 = (yj*z).sum()/z.sum()\n",
    "yj0 =  (yj*(1-z)).sum()/(1-z).sum()\n",
    "\n",
    "x1 = (x*z).sum()/z.sum()\n",
    "x0 =  (x*(1-z)).sum()/(1-z).sum()\n",
    "\n",
    "print (yj1 - yj0)/(x1 - x0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 18\n",
    "\n",
    "They do not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.002870177316993461\n"
     ]
    }
   ],
   "source": [
    "yj1c = (yj*x1c).sum()/x1c.sum()\n",
    "yj0c =  (yj*x0c).sum()/x0c.sum()\n",
    "\n",
    "print yj1c - yj0c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
